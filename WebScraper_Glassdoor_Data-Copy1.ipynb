{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed for scraping\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, TimeoutException\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import time \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path to geckodriver\n",
    "path = \"C:/Users/jpalumbo/geckodriver\"\n",
    "\n",
    "# initialize the webdriver\n",
    "options = webdriver.FirefoxOptions()\n",
    "\n",
    "# assign webdriver path and webdriver options as driver\n",
    "driver = webdriver.Firefox(executable_path=path, options=options)\n",
    "\n",
    "# keyword or job_title to search for within glassdoor url\n",
    "keyword = 'data scientist'            \n",
    "# glassdooor url \n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=' + keyword + '&suggestChosen=false&clickSource=searchBox'\n",
    "\n",
    "# open window with url and search keyword \n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyphrases and keywords to search for in Job_Description assignment during the scrape\n",
    "\n",
    "# keyphrase\n",
    "benefits_keyphrase = ['401 (k)', '401 k', 'paid time off', 'wellness program', 'health savings account', 'health insurance', 'life insurance']\n",
    "qualifications_keyphrase = ['r studio', 'scikit-learn', 'computer science', 'natural language processing', 'deep learning', 'machine learning', \\\n",
    "                            'big data', 'data mining', 'neural networks', 'artificial intelligence', 'power bi', 'google cloud', \\\n",
    "                            'amazon web services', 'pipeline', 'sql', 'nosql', 'ai/ml']\n",
    "# keyword\n",
    "benefits_keyword = ['401(k)', '401k',  'pto', 'dental', 'remote']\n",
    "qualifications_keyword = ['python', 'r', 'r-studio', 'oracle', 'scala', 'pandas', 'numpy', 'pytorch', 'tensorflow', 'spark', 'tableau'\\\n",
    "                          'statistics', 'math', 'mathematics', 'physics', 'engineering', 'nlp', 'engineer', 'algorithms', \\\n",
    "                          'ml', 'ai', 'scraping', 'classification', 'regression', 'aws', 'api', 'bachelors', 'masters', 'phd']   # add 'flask' next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps to get through opening pages\n",
    "\n",
    "time.sleep(random.randint(4,8))      # period to wait for page to load\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"span[class='css-8zxfjs']\"))).click()  # search for data scientist\n",
    "except ElementClickInterceptedException:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"li[class='react-job-listing css-bkasv9 eigr9kq0']\"))).click()  # click on first listing\n",
    "except ElementClickInterceptedException:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"span[class='SVGInline modal_closeIcon']\"))).click() # click out of popup window \n",
    "except ElementClickInterceptedException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []      # create jobs lsit that stores all scraped job dict info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"input[id='sc.location']\")))   # locate, clear and enter location to perform job search\n",
    "location.clear()\n",
    "location.send_keys('Vermont')    # enter location where desired keyword search should take place\n",
    "time.sleep(5)\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"span[class='css-8zxfjs']\"))).click()  # run the job search\n",
    "except ElementClickInterceptedException:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_count = 1                    # a count for the number of web pages that have already been scraped, ends once page_count > pages_per_search\n",
    "count = 1                         # a count for the number of job listings that have already been scraped on current web page, resets every new page\n",
    "count_str = str(count)            # a string form of the count used to insert into xpath in order to find correct element (job_listing) on page\n",
    "pages_per_search = 30             # how many pages to scrape per 'job + location' search\n",
    "jobs_per_page = 30                # how many jobs to scrape per web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 1 Count: 1 Total: 1 Principal, Data Scientist ProServe\n",
      "Page: 1 Count: 2 Total: 2 Sr. Data & ML Engineer\n",
      "Page: 1 Count: 3 Total: 3 Senior Data Analyst\n",
      "Page: 1 Count: 4 Total: 4 Data Scientist - ProServe\n",
      "Page: 1 Count: 5 Total: 5 Senior Director, Risk Management Technology, Data Office\n",
      "Page: 1 Count: 6 Total: 6 Senior Data Scientist\n",
      "Page: 1 Count: 7 Total: 7 Senior Data Scientist - Nationwide Opportunities\n",
      "Page: 1 Count: 8 Total: 8 Lead AI/Machine Learning Engineer\n",
      "Page: 1 Count: 9 Total: 9 Director-Risk Management Technology-Data Office\n",
      "Page: 1 Count: 10 Total: 10 Sr. Data Science Engineer, VMware Cloud on AWS - Opportunity for Working Remotely Burlington, VT\n",
      "Page: 1 Count: 11 Total: 11 Dev Ops Engineer AI/ML\n",
      "Page: 1 Count: 12 Total: 12 AWS Machine Learning (ML) Engineer\n",
      "Page: 1 Count: 13 Total: 13 Sr Data Scientist\n",
      "Page: 1 Count: 14 Total: 14 Data Scientist for Fulfillment\n",
      "Page: 1 Count: 15 Total: 15 Senior Machine Learning Engineer\n",
      "Page: 1 Count: 16 Total: 16 Data Scientist / Machine Learning Engineer (NLP)\n",
      "Page: 1 Count: 17 Total: 17 Data Scientist\n",
      "\n",
      " *****SCRAPING TERMINATED*****\n",
      "Done with page 1\n",
      "\n",
      " *****SCRAPING TERMINATED*****\n"
     ]
    }
   ],
   "source": [
    "# scrapes and stores the data, IF Glassdoor times out, simply re-run \\\n",
    "# this cell and the script will pick up where it left off\n",
    "while page_count <= pages_per_search:\n",
    "    try: \n",
    "        while count <= jobs_per_page:\n",
    "            try: \n",
    "                job_listing = driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[1]/div/div[2]/section/article/div[1]/ul/li[\"+ count_str +\"]\")   # clicks on desired job_listing per page\n",
    "            except NoSuchElementException: \n",
    "                print(\"\\n *****SCRAPING TERMINATED*****\")  # terminate scrape if no jobs exist on the page\n",
    "                break\n",
    "            time.sleep(random.randint(3,6))\n",
    "            job_listing.click()                  # click on the desired job listing\n",
    "            time.sleep(random.randint(3,7))\n",
    "            \n",
    "            # open 'Show More' for job_description text so all text can be scraped - this MUST BE DONE otherwise selenium will only scrape what is visible\n",
    "            show_more = driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[1]/div/div[2]\") \n",
    "            show_more.click()                  # click on the 'show more' portion of the page\n",
    "            time.sleep(random.randint(1,3))\n",
    "\n",
    "            # grab all desired text from each xpath element\n",
    "            try:\n",
    "                try: company_name_rating = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[1]').text\n",
    "                except NoSuchElementException: company_name_rating = -1 \n",
    "\n",
    "                try: job_title = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[2]').text\n",
    "                except NoSuchElementException: job_title = -1 \n",
    "\n",
    "                try: location = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[3]').text\n",
    "                except NoSuchElementException: location = -1 \n",
    "\n",
    "                try: salary_estimate = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[4]/span').text\n",
    "                except NoSuchElementException: salary_estimate = -1 \n",
    "\n",
    "                try: company_size = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[3]/div/div/div[1]/div/div[1]/span[2]').text\n",
    "                except NoSuchElementException: company_size = -1 \n",
    "\n",
    "                try: company_type = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[3]/div/div/div[1]/div/div[3]/span[2]').text\n",
    "                except NoSuchElementException: company_type = -1 \n",
    "\n",
    "                try: company_sector = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[3]/div/div/div[1]/div/div[5]/span[2]').text\n",
    "                except NoSuchElementException: company_sector = -1 \n",
    "\n",
    "                try: year_founded = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[3]/div/div/div[1]/div/div[2]/span[2]').text\n",
    "                except NoSuchElementException: year_founded = -1 \n",
    "\n",
    "                try: company_industry = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[3]/div/div/div[1]/div/div[4]/span[2]').text\n",
    "                except NoSuchElementException: company_industry = -1 \n",
    "\n",
    "                try: company_revenue = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[3]/div/div/div[1]/div/div[6]/span[2]').text\n",
    "                except NoSuchElementException: company_revenue = -1 \n",
    "\n",
    "                try: job_description = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/div/div/article/div/div[2]/div[1]/div[1]/div/div[1]/div').text\n",
    "                except NoSuchElementException: job_description = -1 \n",
    "            except:\n",
    "                time.sleep(3)     \n",
    "\n",
    "            ### lists to contain keyphrases and keywords from the job_description text\n",
    "            benefits_list = []\n",
    "            qualifications_list = []\n",
    "\n",
    "            # make all elements in job_description string lowercase\n",
    "            job_description = job_description.lower()\n",
    "\n",
    "            # append benefits keyphrases to benefits list\n",
    "            for i in benefits_keyphrase:\n",
    "                if i in job_description:\n",
    "                    benefits_list.append(i)\n",
    "\n",
    "            # append qualifications keyphrases to qualifications list \n",
    "            for i in qualifications_keyphrase:\n",
    "                if i in job_description:\n",
    "                    qualifications_list.append(i)\n",
    "\n",
    "            # create job_description word list using regex to isolate terms\n",
    "            description_list = [i.lower() for i in re.split('\\s|(?<!\\d)[,.]|[,.](?!\\d)', job_description)]\n",
    "\n",
    "            # append benefits key words to benefits list\n",
    "            for i in benefits_keyword:\n",
    "                if i in description_list:\n",
    "                    benefits_list.append(i)\n",
    "\n",
    "            # append qualifications key words to qualifications list \n",
    "            for i in qualifications_keyword:\n",
    "                    if i in description_list:\n",
    "                        qualifications_list.append(i)\n",
    "\n",
    "            # add scraped jobs data to 'jobs' dictioanry created above\n",
    "            jobs.append({\"Company_Name_Rating\": company_name_rating, \n",
    "                        \"Job_Title\": job_title,\n",
    "                        \"Location\": location,\n",
    "                        \"Salary_Estimate\": salary_estimate,\n",
    "                        \"Company_Size\": company_size,\n",
    "                        \"Company_Type\": company_type,\n",
    "                        \"Company_Sector\": company_sector,\n",
    "                        \"Year_Founded\": year_founded,\n",
    "                        \"Company_Industry\": company_industry,\n",
    "                        \"Company_Revenue\": company_revenue,\n",
    "                        \"Job_Benefits\": benefits_list,\n",
    "                        \"Job_Qualifications\": qualifications_list})\n",
    "            \n",
    "            # after each job scrape, print page_count, job count for that page, and overall scrape count for entire scrape\n",
    "            if page_count == 1:\n",
    "                print(\"Page:\", page_count, \"Count:\", count, \"Total:\", count, job_title)\n",
    "            if page_count > 1:\n",
    "                print(\"Page:\", page_count, \"Count:\", count, \"Total:\", (count+((page_count*30)-30)), job_title)\n",
    "            \n",
    "            # reset lists and increase count for next iteration of the while loop\n",
    "            benefits_list = []\n",
    "            qualifications_list = []\n",
    "            count += 1\n",
    "            count_str = str(count)\n",
    "\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "    \n",
    "    # once done with an entire page, print done with page_count and reset count and increase page_count by 1\n",
    "    print(f\"Done with page {page_count}\")\n",
    "    page_count += 1\n",
    "    count = 1\n",
    "    count_str = str(count)\n",
    "    \n",
    "    # click on next page to scrape\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"li[class='job-search-key-106v8g7 e1gri00l2']\"))).click()\n",
    "        time.sleep(random.randint(4,7))\n",
    "    except TimeoutException:\n",
    "            print(\"\\n *****SCRAPING TERMINATED*****\")  # terminate scrape if no more pages to scrape\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)    # check length of jobs as a sanity check to make sure it makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Estimate</th>\n",
       "      <th>Company_Size</th>\n",
       "      <th>Company_Type</th>\n",
       "      <th>Company_Sector</th>\n",
       "      <th>Year_Founded</th>\n",
       "      <th>Company_Industry</th>\n",
       "      <th>Company_Revenue</th>\n",
       "      <th>Job_Benefits</th>\n",
       "      <th>Job_Qualifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon Web Services, Inc.\\n3.8</td>\n",
       "      <td>Sr. Data &amp; ML Engineer</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>Employer Provided Salary:$122K</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>1994</td>\n",
       "      <td>Internet</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>[remote]</td>\n",
       "      <td>[computer science, deep learning, machine lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Web Services, Inc.\\n3.8</td>\n",
       "      <td>Data Scientist - ProServe</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>Employer Provided Salary:$115K</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>1994</td>\n",
       "      <td>Internet</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>[remote]</td>\n",
       "      <td>[scikit-learn, computer science, natural langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VMware\\n4.3</td>\n",
       "      <td>Sr. Data Science Engineer, VMware Cloud on AWS...</td>\n",
       "      <td>Burlington, VT</td>\n",
       "      <td>$68K - $157K (Glassdoor est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>1998</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>$5 to $10 billion (USD)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[computer science, sql, mathematics, engineeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Attadale Partners, LLC</td>\n",
       "      <td>Data Scientist / Machine Learning Engineer (NLP)</td>\n",
       "      <td>United States</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[paid time off, health savings account, health...</td>\n",
       "      <td>[computer science, natural language processing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Change Healthcare\\n3.3</td>\n",
       "      <td>Dev Ops Engineer AI/ML</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[computer science, deep learning, machine lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_Name_Rating  \\\n",
       "1   Amazon Web Services, Inc.\\n3.8   \n",
       "3   Amazon Web Services, Inc.\\n3.8   \n",
       "9                      VMware\\n4.3   \n",
       "15          Attadale Partners, LLC   \n",
       "10          Change Healthcare\\n3.3   \n",
       "\n",
       "                                            Job_Title        Location  \\\n",
       "1                              Sr. Data & ML Engineer         Vermont   \n",
       "3                           Data Scientist - ProServe         Vermont   \n",
       "9   Sr. Data Science Engineer, VMware Cloud on AWS...  Burlington, VT   \n",
       "15   Data Scientist / Machine Learning Engineer (NLP)   United States   \n",
       "10                             Dev Ops Engineer AI/ML         Vermont   \n",
       "\n",
       "                   Salary_Estimate      Company_Size      Company_Type  \\\n",
       "1   Employer Provided Salary:$122K  10000+ Employees  Company - Public   \n",
       "3   Employer Provided Salary:$115K  10000+ Employees  Company - Public   \n",
       "9    $68K - $157K (Glassdoor est.)  10000+ Employees  Company - Public   \n",
       "15                              -1                -1                -1   \n",
       "10                              -1                -1                -1   \n",
       "\n",
       "            Company_Sector Year_Founded              Company_Industry  \\\n",
       "1   Information Technology         1994                      Internet   \n",
       "3   Information Technology         1994                      Internet   \n",
       "9   Information Technology         1998  Computer Hardware & Software   \n",
       "15                      -1           -1                            -1   \n",
       "10                      -1           -1                            -1   \n",
       "\n",
       "            Company_Revenue  \\\n",
       "1        $10+ billion (USD)   \n",
       "3        $10+ billion (USD)   \n",
       "9   $5 to $10 billion (USD)   \n",
       "15                       -1   \n",
       "10                       -1   \n",
       "\n",
       "                                         Job_Benefits  \\\n",
       "1                                            [remote]   \n",
       "3                                            [remote]   \n",
       "9                                                  []   \n",
       "15  [paid time off, health savings account, health...   \n",
       "10                                                 []   \n",
       "\n",
       "                                   Job_Qualifications  \n",
       "1   [computer science, deep learning, machine lear...  \n",
       "3   [scikit-learn, computer science, natural langu...  \n",
       "9   [computer science, sql, mathematics, engineeri...  \n",
       "15  [computer science, natural language processing...  \n",
       "10  [computer science, deep learning, machine lear...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn dictionary object into a pandas dataframe\n",
    "df = pd.DataFrame(jobs) \n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the dataframe to a csv \n",
    "df.to_csv('data/glassdoor_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
